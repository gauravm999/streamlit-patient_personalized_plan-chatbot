# -*- coding: utf-8 -*-
"""Patient Personalized Healthcare Recommendations_RAG_CHATBOT_28042025_STREAMLIT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OUbTYxF8w3gTCuu5AYq0em_BjqQ1lXbi
"""

# # Install required packages
# !pip install streamlit
# !pip install openai langchain faiss-cpu pandas sentence-transformers
# !pip install -U langchain-community
# !pip install tiktoken

# app.py

# --- Import Libraries ---
import streamlit as st
import os
import glob
import pandas as pd
from dotenv import load_dotenv
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI

# --- Streamlit Page Config ---
st.set_page_config(page_title="Patient Healthcare Chatbot", page_icon="ğŸ©º")
st.title("ğŸ¥ Patient Personalized Healthcare Recommendations Chatbot")

# --- Load Environment Variables ---
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

if not openai_key:
    st.error("ğŸš¨ OpenAI API key not found! Please check your .env file.")
    st.stop()

# --- Sidebar: Upload Files ---
st.sidebar.header("ğŸ“ Upload Data Files")
uploaded_csv = st.sidebar.file_uploader("Upload patient_records.csv", type="csv")
uploaded_txts = st.sidebar.file_uploader("Upload patient_notes (.txt)", type="txt", accept_multiple_files=True)

if uploaded_csv and uploaded_txts:
    # --- Load Structured Data ---
    df = pd.read_csv(uploaded_csv)

    structured_texts = df.apply(
        lambda row: f"Patient ID: {row['Patient_ID']}, Age: {row['Age']}, Gender: {row['Gender']}, BMI: {row['BMI']}, Blood Pressure: {row['Blood_Pressure']}, Cholesterol: {row['Cholesterol']}, Diagnosis: {row['Diagnosis']}, Recommended Treatment: {row['Recommended_Treatment']}",
        axis=1
    ).tolist()

    # --- Load Unstructured Data ---
    unstructured_texts = [file.read().decode('utf-8') for file in uploaded_txts]

    # --- Combine all texts ---
    all_texts = structured_texts + unstructured_texts

    st.success(f"âœ… Loaded {len(all_texts)} documents successfully!")

    # --- Setup FAISS Vector Store ---
    with st.spinner("ğŸ”„ Setting up vector store..."):
        embeddings = OpenAIEmbeddings(openai_api_key=os.getenv("OPENAI_API_KEY"))
        vector_store = FAISS.from_texts(all_texts, embeddings)

    # --- Setup Conversational Retrieval Chain ---
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0, openai_api_key=os.getenv("OPENAI_API_KEY"))
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    rag_chain = ConversationalRetrievalChain.from_llm(
        llm,
        retriever=vector_store.as_retriever(),
        memory=memory
    )

    # --- Chat Section ---
    st.subheader("ğŸ’¬ Ask Personalized Healthcare Questions")
    if "messages" not in st.session_state:
        st.session_state.messages = []

    user_input = st.text_input("Type your question:", key="input")

    if st.button("Ask"):
        if user_input:
            with st.spinner("ğŸ¤” Thinking..."):
                response = rag_chain({"question": user_input})
                answer = response['answer']

            st.session_state.messages.append(("You", user_input))
            st.session_state.messages.append(("Bot", answer))

    # --- Display Chat Messages ---
    for sender, message in st.session_state.messages:
        if sender == "You":
            st.markdown(f"**ğŸ§‘â€ğŸ’¼ {sender}:** {message}")
        else:
            st.markdown(f"**ğŸ¤– {sender}:** {message}")

else:
    st.warning("ğŸ“„ Please upload **patient_records.csv** and at least one **patient_notes.txt** file.")